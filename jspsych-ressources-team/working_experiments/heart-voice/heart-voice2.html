<!DOCTYPE html>
<html>
<head>
  <title>PDS jsPsych Demo</title>

  <!-- Load libraries -->
  <script src="../../../lib/jspsych-7.3.0/dist/jspsych.js"></script>

  <!-- Load jsPsych plug-ins -->
  <script src="../../../lib/jspsych-7.3.0/dist/plugin-html-button-response.js" type="text/javascript"></script>
  <script src="../../../lib/jspsych-7.3.0/dist/plugin-html-keyboard-response.js" type="text/javascript"></script>
  <script src="../../../lib/jspsych-7.3.0/dist/plugin-video-button-response.js" type="text/javascript"></script>
  <script src="../../../lib/jspsych-7.3.0/dist/plugin-preload.js" type="text/javascript"></script>
  <!-- Load CSS styles -->
  <link href="../../../lib/jspsych-7.3.0/dist/jspsych.css" rel="stylesheet" type="text/css"></link>
  
</head>
<body></body>
<script>
/*

Code of the experiment of Nadia Guerrouaou.
Inspired by Galvez-Pol et al's (2022) results describing our ability to depict HR on faces, we are investigating if this ability can be observed in voice and how the pitch could be a most relevant acoustical parameters in this matter, if true.

2023/03/18

AUTHOR: Matthieu Fraticelli / fraticelli.matthieu@hotmail.fr

*/

  /* _______________________________________________________________________________________
PARAMETRES */

  
const VIDEOS = [
  "vid/TEST1.mp4",
  "vid/TEST1.mp4",
  "vid/TEST1.mp4",
  "vid/TEST1.mp4",
  ];



//__________________________________________________________________________________________


// Initialize jsPsych
  
var jsPsych = initJsPsych({
      //show_progress_bar: true,
      on_finish: function() {
      //jsPsych.data.displayData(); 
        jsPsych.data.get().localSave('csv','mydata.csv');
       },
      on_trial_start: function() {
       },
      on_trial_finish: function(){
       },
    }); 
  
  
// Initialize timeline.
var timeline = [];

  
//CODE BELOW -------------------------------------------------------------------------------------------------------------



//creating of the pairs  
var arrayElements = VIDEOS;


const pairsOfArray = array => (
  array.reduce((acc, val, i1) => [
    ...acc,
    ...new Array(array.length - 1 - i1).fill(0)
      .map((v, i2) => ([array[i1], array[i1 + 1 + i2]]))
  ], [])
) 

//The new array with all the pairs.
var pairsArray = pairsOfArray(jsPsych.randomization.shuffle(arrayElements));
pairsArray = jsPsych.randomization.shuffle(pairsArray)
console.log(pairsArray)

 
//preload sound and video     
var preload = {
   type: jsPsychPreload,
   video: VIDEOS,
  };
    
timeline.push(preload);
 
  
var numbVidsEval = arrayElements.length
console.log(`Number of videos is: ${numbVidsEval}`)

var numbVideosEvalPairs = pairsArray.length
console.log(`Number of videos pairs is: ${numbVideosEvalPairs}`)

var test = {
  type: jsPsychHtmlButtonResponse,
  stimulus: 'Démonstration',
  choices: ['Start'],
};

timeline.push(test)

// a few variables used in the code in order to check answers of the participants.
 var rep;
 var whitchVideo = ['','']; 
 var viewedVideo = [false,false]; 
 var choosedVideo;


 /*var preloadBeforeTask = {
    type: jsPsychPreload,
    video: function(){
      return [pairsArray[i][0], pairsArray[i][1]]
    },
  };*/
    

 // The part that is going to display the videos, I'm using an HTMK keybord response to display both videos using <video> tag.
 var videoTask = {
        
        type: jsPsychHtmlKeyboardResponse,
        stimulus: function(){
          return `<p style="font-size: 25px">

           <b>Début de l'évaluation</b></p>

           <hr>

           <p>Vous allez visionner deux vidéos différentes avec une paire voix et rythme cardiaque.</p>

           <p>Indiquez quelle paire vous parait être la plus associée.</p>

           <hr>

           

            <div style="display: flex; justify-content: space-between;"">

                <video width="320" height="240" ${whitchVideo[0]}>
                   <source src="${pairsArray[i][0]}" type="video/mp4">
                </video>

                <video width="320" height="240" ${whitchVideo[1]}>
                   <source src="${pairsArray[i][1]}" type="video/mp4">
                </video>

          </div>

          <hr>

           <p style="font-size: 15px">
            <i>
              Utilisez les flèches du clavier pour visionner les vidéos. 
            </i>
          </p>

          <span style="font-size:15px;border: 1px solid #ccc; line-height: 1.4;color: #333;padding: 7.5px 20px; font-family: sans-serif; background-color: white; margin: 5px; border-radius: 5px;"><b style="font-size: 18px">←</b></span>
          
          <span style="font-size:15px;border: 1px solid #ccc; line-height: 1.4;color: #333;padding: 7.5px 20px; font-family: sans-serif; background-color: white; margin: 5px; border-radius: 5px;"><b style="font-size: 18px">→</b></span>
    
      <p></p>

          <hr>

          <p style="font-size: 20px">
            <b>Réponse</b>
          </p>
          <p style="font-size: 15px">
            <i>
              Appuyez sur les touches suivantes pour répondre :
            </i>
          </p>

           <span style="font-size:15px;border: 1px solid #ccc; line-height: 1.4;color: #333;padding: 7.5px 20px; font-family: sans-serif; background-color: white; margin: 5px; border-radius: 5px;"><b style="font-size: 18px">A</b></span>
          
          <span style="font-size:15px;border: 1px solid #ccc; line-height: 1.4;color: #333;padding: 7.5px 20px; font-family: sans-serif; background-color: white; margin: 5px; border-radius: 5px;"><b style="font-size: 18px">B</b></span>

          `
        },
        /*button_html:[
          '<button class="jspsych-btn" style = "position:absolute; left:450px; top: 680px">%choice%</button>', '<button class="jspsych-btn" style = "position:absolute; right:450px; top: 680px">%choice%</button>'], */
        prompt: ``,
        on_start: function(){
           },
        on_finish: function(){
          rep = jsPsych.data.getLastTrialData().trials[0].response
          console.log(`Response is: ${rep}`)
          return rep
        },
        choices: ['A', 'B', 'a', 'b', 'ArrowLeft','ArrowRight'],
        post_trial_gap: 0,
        
      };




// The loop of the video displayed, in order to watch them as many times as wanted and to respond afterwards.
  var loopVideoTask = {
    timeline: [videoTask],
    loop_function: function(){
      console.log(`videos ${viewedVideo}`)
      if(rep === 'A' || rep === 'a'){
        if(viewedVideo[0] === true && viewedVideo[1] === true){
          console.log(`Response is A, viewedVideo is true no Loop!`)
            viewedVideo[0] = false
            viewedVideo[1] = false
            console.log(`Reset viewedcheck`)
            whitchVideo[0] = ''
            whitchVideo[1] = ''
            console.log(whitchVideo)
            choosedVideo = pairsArray[i][0]
            console.log(`Video choosed: ${choosedVideo}`)
          return false
        } else {
          alert("Vous devez regarder les deux vidéos avant de répondre !")
          console.log('Not both video viewed!')
          whitchVideo[0] = ''
          whitchVideo[1] = ''
          console.log(whitchVideo)
          return true
        }
      } else if(rep === 'B' || rep === 'b'){
        if(viewedVideo[0] === true && viewedVideo[1] === true){
          console.log(`Response is B, viewedVideo is true no Loop!`)
            viewedVideo[0] = false
            viewedVideo[1] = false
            console.log(`Reset viewedcheck`)
            whitchVideo[0] = ''
            whitchVideo[1] = ''
            console.log(whitchVideo)
            choosedVideo = pairsArray[i][1]
            console.log(`Video choosed: ${choosedVideo}`)
          return false
        } else {
          alert("Vous devez regarder les deux vidéos avant de répondre !")
          console.log('Not both video viewed!')
          whitchVideo[0] = ''
          whitchVideo[1] = ''
          console.log(whitchVideo)
          return true
        }
      } else if(rep === 'arrowleft'){
        whitchVideo[0] = 'autoplay'
        whitchVideo[1] = ''
        console.log(whitchVideo)
        viewedVideo[0] = true
        console.log(viewedVideo)
        console.log(`Response is Left, Loop!`)
        return true
      } else if(rep === 'arrowright'){
        whitchVideo[0] = ''
        whitchVideo[1] = 'autoplay'
        console.log(whitchVideo)
        viewedVideo[1] = true
        console.log(viewedVideo)
        console.log(`Response is Right, Loop!`)
        return true
      }
    },
  };


  // ISI cross fixation between trials.
  var interTrial = {
    type: jsPsychHtmlKeyboardResponse,
    stimulus: `<p style="font-size: 70px">+</p>`,
    choices: ["NO_KEYS"],
    trial_duration: 2000,
    data: function(){
      return {
        task: 'REPONSE SUJET',
        videoShowed: `${pairsArray[i]}`,
        videoChoosed: `${choosedVideo}`,
      }
    }
  };


  //to increment in the main loop
  var i = 0; 
  
  // The main loop for the task, with the experimental routine, depending of the number of video pairs. 
  var loopTask = {
    timeline: [
      //preloadBeforeTask,
      loopVideoTask,
      interTrial,
      ],
    loop_function: function(){
      console.log(i)
      if(i < numbVideosEvalPairs-1){
        i++
        console.log(`i = ${i}`)
        return true
      } else {
        i = 0
        console.log(`Loop is over`)
        return false
      }
    },
  };

  timeline.push(loopTask)

  
// END CODE ABOVE -------------------------------------------------------------------------------------------------------------

jsPsych.run(timeline);
  
</script>
</html>
